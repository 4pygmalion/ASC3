{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "REV_DIR = os.getcwd()\n",
    "RES_DIR = os.path.dirname(REV_DIR)\n",
    "ROOT_DIR = os.path.dirname(RES_DIR)\n",
    "sys.path.append(ROOT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUROC의 t-test 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/heon/anaconda3/envs/3asc/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading artifacts: 100%|██████████| 1/1 [00:09<00:00,  9.57s/it]\n",
      "Downloading artifacts: 100%|██████████| 1/1 [00:10<00:00, 10.51s/it]\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "\n",
    "\n",
    "from results.revision.revision_utils import  TRACKING_URI, RF_RUN_ID, BOOSTRAP_RUN_ID\n",
    "from utils.serialization_ops import load_pickle\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "\n",
    "path = mlflow.artifacts.download_artifacts(\"mlflow-artifacts:/6/{run_id}/artifacts/fold_result.pickle\".format(run_id=RF_RUN_ID))\n",
    "fold_results_rf = load_pickle(path)\n",
    "\n",
    "all_aurocs_rf = list()\n",
    "n_folds = len(fold_results_rf[\"test_ids\"])\n",
    "for fold in range(n_folds):\n",
    "    fold_bag_y_trues = fold_results_rf[\"fold_bag_y_trues\"][fold]\n",
    "    fold_bag_y_probs = fold_results_rf[\"fold_bag_y_probs\"][fold]\n",
    "    fpr, tpr, _ = roc_curve(fold_bag_y_trues, fold_bag_y_probs)\n",
    "    all_aurocs_rf.append([fold, auc(fpr, tpr), \"RF\"])\n",
    "\n",
    "\n",
    "path = mlflow.artifacts.download_artifacts(\"mlflow-artifacts:/6/{run_id}/artifacts/fold_result.pickle\".format(run_id=BOOSTRAP_RUN_ID))\n",
    "fold_results_mil = load_pickle(path)\n",
    "n_folds = len(fold_results_mil[\"test_ids\"])\n",
    "all_aurocs_mil = list()\n",
    "for fold in range(n_folds):\n",
    "    fold_bag_y_trues = fold_results_mil[\"fold_bag_y_trues\"][fold]\n",
    "    fold_bag_y_probs = fold_results_mil[\"fold_bag_y_probs\"][fold]\n",
    "    fpr, tpr, _ = roc_curve(fold_bag_y_trues, fold_bag_y_probs)\n",
    "    all_aurocs_mil.append([fold, auc(fpr, tpr), \"MIL\"])\n",
    "    \n",
    "auroc_df = pd.DataFrame(all_aurocs_rf + all_aurocs_mil, columns=[\"fold\", \"AUC\", \"Method\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/heon/dev/ASC3/dataset_positive_negative.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mresults\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrevision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrevision_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DATA_PATH\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PatientDataSet\n\u001b[0;32m----> 5\u001b[0m patient_dataset:PatientDataSet \u001b[38;5;241m=\u001b[39m \u001b[43mload_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDATA_PATH\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/ASC3/utils/serialization_ops.py:12\u001b[0m, in \u001b[0;36mload_pickle\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_pickle\u001b[39m(path):\n\u001b[0;32m---> 12\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fh:\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mload(fh)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/heon/dev/ASC3/dataset_positive_negative.pickle'"
     ]
    }
   ],
   "source": [
    "from utils.serialization_ops import load_pickle\n",
    "from results.revision.revision_utils import DATA_PATH\n",
    "from core.data_model import PatientDataSet\n",
    "\n",
    "patient_dataset:PatientDataSet = load_pickle(DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SNV + CNV Top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from core.metric import topk_recall\n",
    "from results.revision.revision_utils import get_topk_folds\n",
    "\n",
    "performnace_rf_snv_cnv = get_topk_folds(\n",
    "    fold_results_rf[\"fold_instance_y_trues\"],\n",
    "    fold_results_rf[\"fold_instance_y_probs\"]\n",
    ")\n",
    "performnace_mil_snv_cnv = get_topk_folds(\n",
    "    fold_results_mil[\"fold_instance_y_trues\"],\n",
    "    fold_results_mil[\"fold_instance_y_probs\"]\n",
    ")\n",
    "\n",
    "\n",
    "ks = [1, 2, 3, 4, 5, 10, 15, 20, 100]\n",
    "performance_rf_snv_cnv = pd.DataFrame(performnace_rf_snv_cnv, columns=ks)\n",
    "performance_rf_snv_cnv[\"Method\"] = \"RF\"\n",
    "\n",
    "performance_mil_snv_cnv = pd.DataFrame(performnace_mil_snv_cnv, columns=ks)\n",
    "performance_mil_snv_cnv[\"Method\"] = \"MIL\"\n",
    "\n",
    "\n",
    "snv_cnv_topk = pd.concat([performance_rf_snv_cnv,performance_mil_snv_cnv])\n",
    "snv_cnv_topk = snv_cnv_topk.melt(id_vars=[\"Method\"], var_name=\"K\", value_name=\"Value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SNV Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from results.revision.revision_utils import get_snv_only_case\n",
    "\n",
    "fold_results_rf_snv = {\"fold_instance_y_trues\":list(), \"fold_instance_y_probs\":list()}\n",
    "fold_results_mil_snv = {\"fold_instance_y_trues\":list(), \"fold_instance_y_probs\":list()}\n",
    "for fold_idx in range(n_folds):\n",
    "    test_ids = fold_results_rf[\"test_ids\"][fold_idx]\n",
    "    snv_only_ids = get_snv_only_case(patient_dataset[test_ids])  \n",
    "    test_indices = [test_ids.index(snv_id) for snv_id in snv_only_ids]\n",
    "    instance_y_trues = [fold_results_rf[\"fold_instance_y_trues\"][fold_idx][_id] for _id in test_indices]\n",
    "    instance_y_probs = [fold_results_rf[\"fold_instance_y_probs\"][fold_idx][_id] for _id in test_indices]\n",
    "    fold_results_rf_snv[\"fold_instance_y_trues\"].append(instance_y_trues)\n",
    "    fold_results_rf_snv[\"fold_instance_y_probs\"].append(instance_y_probs)\n",
    "\n",
    "    test_ids = fold_results_rf[\"test_ids\"][fold_idx]\n",
    "    snv_only_ids = get_snv_only_case(patient_dataset[test_ids])  \n",
    "    test_indices = [test_ids.index(snv_id) for snv_id in snv_only_ids]\n",
    "    instance_y_trues = [fold_results_mil[\"fold_instance_y_trues\"][fold_idx][_id] for _id in test_indices]\n",
    "    instance_y_probs = [fold_results_mil[\"fold_instance_y_probs\"][fold_idx][_id] for _id in test_indices]\n",
    "    fold_results_mil_snv[\"fold_instance_y_trues\"].append(instance_y_trues)\n",
    "    fold_results_mil_snv[\"fold_instance_y_probs\"].append(instance_y_probs)\n",
    "\n",
    "performnace_rf_snv = get_topk_folds(\n",
    "    fold_results_rf_snv[\"fold_instance_y_trues\"],\n",
    "    fold_results_rf_snv[\"fold_instance_y_probs\"]\n",
    ")\n",
    "performnace_mil_snv = get_topk_folds(\n",
    "    fold_results_mil_snv[\"fold_instance_y_trues\"],\n",
    "    fold_results_mil_snv[\"fold_instance_y_probs\"]\n",
    ")\n",
    "\n",
    "ks = [1, 2, 3, 4, 5, 10, 15, 20, 100]\n",
    "performance_rf_snv = pd.DataFrame(performnace_rf_snv, columns=ks)\n",
    "performance_rf_snv[\"Method\"] = \"RF\"\n",
    "\n",
    "performance_mil_snv = pd.DataFrame(performnace_mil_snv, columns=ks)\n",
    "performance_mil_snv[\"Method\"] = \"MIL\"\n",
    "\n",
    "\n",
    "snv_topk = pd.concat([performance_rf_snv,performance_mil_snv])\n",
    "snv_topk = snv_topk.melt(id_vars=[\"Method\"], var_name=\"K\", value_name=\"Value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNV only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from results.revision.revision_utils import get_cnv_only_case\n",
    "from core.metric import Metric\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fold_results_rf_cnv = {\"fold_instance_y_trues\":list(), \"fold_instance_y_probs\":list()}\n",
    "fold_results_mil_cnv = {\"fold_instance_y_trues\":list(), \"fold_instance_y_probs\":list()}\n",
    "for fold_idx in range(n_folds):\n",
    "    test_ids = fold_results_rf[\"test_ids\"][fold_idx]\n",
    "    cnv_only_ids = get_cnv_only_case(patient_dataset[test_ids])  \n",
    "    test_indices = [test_ids.index(snv_id) for snv_id in cnv_only_ids]\n",
    "    instance_y_trues = [fold_results_rf[\"fold_instance_y_trues\"][fold_idx][_id] for _id in test_indices]\n",
    "    instance_y_probs = [fold_results_rf[\"fold_instance_y_probs\"][fold_idx][_id] for _id in test_indices]\n",
    "    fold_results_rf_cnv[\"fold_instance_y_trues\"].append(instance_y_trues)\n",
    "    fold_results_rf_cnv[\"fold_instance_y_probs\"].append(instance_y_probs)\n",
    "\n",
    "    test_ids = fold_results_mil[\"test_ids\"][fold_idx]\n",
    "    cnv_only_ids = get_cnv_only_case(patient_dataset[test_ids])\n",
    "    test_indices = [test_ids.index(snv_id) for snv_id in cnv_only_ids]\n",
    "    instance_y_trues = [fold_results_mil[\"fold_instance_y_trues\"][fold_idx][_id] for _id in test_indices]\n",
    "    instance_y_probs = [fold_results_mil[\"fold_instance_y_probs\"][fold_idx][_id] for _id in test_indices]\n",
    "    fold_results_mil_cnv[\"fold_instance_y_trues\"].append(instance_y_trues)\n",
    "    fold_results_mil_cnv[\"fold_instance_y_probs\"].append(instance_y_probs)\n",
    "\n",
    "performnace_rf_cnv = get_topk_folds(\n",
    "    fold_results_rf_cnv[\"fold_instance_y_trues\"],\n",
    "    fold_results_rf_cnv[\"fold_instance_y_probs\"]\n",
    ")\n",
    "performnace_mil_cnv = get_topk_folds(\n",
    "    fold_results_mil_cnv[\"fold_instance_y_trues\"],\n",
    "    fold_results_mil_cnv[\"fold_instance_y_probs\"]\n",
    ")\n",
    "\n",
    "ks = [1, 2, 3, 4, 5, 10, 15, 20, 100]\n",
    "performance_rf_cnv = pd.DataFrame(performnace_rf_cnv, columns=ks)\n",
    "performance_rf_cnv[\"Method\"] = \"RF\"\n",
    "\n",
    "performance_mil_cnv = pd.DataFrame(performnace_mil_cnv, columns=ks)\n",
    "performance_mil_cnv[\"Method\"] = \"MIL\"\n",
    "\n",
    "\n",
    "cnv_topk = pd.concat([performance_rf_cnv,performance_mil_cnv])\n",
    "cnv_topk = cnv_topk.melt(id_vars=[\"Method\"], var_name=\"K\", value_name=\"Value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-\"*30 + \"AVG\" + \"-\"*30)\n",
    "print(performnace_mil_cnv.mean(axis=0) * 100)\n",
    "print(\"-\"*30 + \"Lower CI\" + \"-\"*30)\n",
    "print(np.quantile(performnace_mil_cnv, q=0.05, axis=0) * 100)\n",
    "print(\"-\"*30 + \"Upper CI\" + \"-\"*30)\n",
    "print(np.quantile(performnace_mil_cnv, q=0.95, axis=0) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### All Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot\n",
    "import seaborn as sns \n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import ttest_ind\n",
    "from statannot import add_stat_annotation\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "\n",
    "from results.revision.revision_utils import cohen_d\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "\n",
    "sns.boxplot(\n",
    "    data=auroc_df,\n",
    "    x=\"Method\",\n",
    "    y=\"AUC\",\n",
    "    ax=axes[0]\n",
    ")\n",
    "pairs = [\n",
    "    (\"RF\", \"MIL\")\n",
    "]\n",
    "t_stat, p_value = ttest_ind(\n",
    "    auroc_df.loc[auroc_df[\"Method\"]==\"MIL\"][\"AUC\"], \n",
    "    auroc_df.loc[auroc_df[\"Method\"]==\"RF\"][\"AUC\"], \n",
    "    equal_var=False\n",
    ")\n",
    "d = cohen_d(auroc_df.loc[auroc_df[\"Method\"]==\"MIL\"][\"AUC\"], auroc_df.loc[auroc_df[\"Method\"]==\"RF\"][\"AUC\"])\n",
    "print(f\"AUC - Cohen's d: {d}\")\n",
    "add_stat_annotation(\n",
    "    axes[0],\n",
    "    data=auroc_df,\n",
    "    x=\"Method\",\n",
    "    y=\"AUC\",\n",
    "    box_pairs=pairs,\n",
    "    perform_stat_test=False,\n",
    "    text_format='star',\n",
    "    loc='inside',\n",
    "    verbose=0,\n",
    "    comparisons_correction=None,\n",
    "    pvalues=[p_value],\n",
    ")\n",
    "axes[0].set_title(\"AUROC comparision (genetic testing conclusion):\\n MIL vs RF(Max pooling)\")\n",
    "\n",
    "####### SNV+CNV\n",
    "sns.boxplot(\n",
    "    data=snv_cnv_topk,\n",
    "    x=\"K\",\n",
    "    y=\"Value\",\n",
    "    hue=\"Method\",\n",
    "    ax=axes[1]\n",
    "    \n",
    ")\n",
    "pairs = [\n",
    "    ((k, \"RF\"), (k, \"MIL\"))\n",
    "    for k in [1, 2, 3, 4, 5, 10, 15, 20, 100]\n",
    "]\n",
    "p_valeus = [\n",
    "    ttest_ind(\n",
    "        snv_cnv_topk.loc[(snv_cnv_topk[\"K\"]==k) & (snv_cnv_topk[\"Method\"]==\"RF\")][\"Value\"],\n",
    "        snv_cnv_topk.loc[(snv_cnv_topk[\"K\"]==k) & (snv_cnv_topk[\"Method\"]==\"MIL\")][\"Value\"],\n",
    "    ).pvalue\n",
    "    for k in [1, 2, 3, 4, 5, 10, 15, 20, 100]\n",
    "]\n",
    "add_stat_annotation(\n",
    "    axes[1],\n",
    "    data=snv_cnv_topk,\n",
    "    x=\"K\",\n",
    "    y=\"Value\",\n",
    "    hue=\"Method\",\n",
    "    box_pairs=pairs,\n",
    "    perform_stat_test=False,\n",
    "    text_format='star',\n",
    "    loc='inside',\n",
    "    verbose=0,\n",
    "    comparisons_correction=None,\n",
    "    pvalues=p_valeus,\n",
    ")\n",
    "axes[1].set_title(\"Hit rate (SNV+CNV)\")\n",
    "\n",
    "####### SNV\n",
    "sns.boxplot(\n",
    "    data=snv_topk,\n",
    "    x=\"K\",\n",
    "    y=\"Value\",\n",
    "    hue=\"Method\",\n",
    "    ax=axes[2]\n",
    ")\n",
    "pairs = [\n",
    "    ((k, \"RF\"), (k, \"MIL\"))\n",
    "    for k in [1, 2, 3, 4, 5, 10, 15, 20, 100]\n",
    "]\n",
    "p_valeus = [\n",
    "    ttest_ind(\n",
    "        snv_topk.loc[(snv_topk[\"K\"]==k) & (snv_topk[\"Method\"]==\"RF\")][\"Value\"],\n",
    "        snv_topk.loc[(snv_topk[\"K\"]==k) & (snv_topk[\"Method\"]==\"MIL\")][\"Value\"],\n",
    "    ).pvalue\n",
    "    for k in [1, 2, 3, 4, 5, 10, 15, 20, 100]\n",
    "]\n",
    "add_stat_annotation(\n",
    "    axes[2],\n",
    "    data=snv_topk,\n",
    "    x=\"K\",\n",
    "    y=\"Value\",\n",
    "    hue=\"Method\",\n",
    "    box_pairs=pairs,\n",
    "    perform_stat_test=False,\n",
    "    text_format='star',\n",
    "    loc='inside',\n",
    "    verbose=0,\n",
    "    comparisons_correction=None,\n",
    "    pvalues=p_valeus,\n",
    ")\n",
    "axes[2].set_title(\"Hit rate (SNV Only)\")\n",
    "\n",
    "####### CNV\n",
    "sns.boxplot(\n",
    "    data=cnv_topk,\n",
    "    x=\"K\",\n",
    "    y=\"Value\",\n",
    "    hue=\"Method\",\n",
    "    ax=axes[3]\n",
    ")\n",
    "pairs = [\n",
    "    ((k, \"RF\"), (k, \"MIL\"))\n",
    "    for k in [1, 2, 3, 4, 5, 10, 15, 20, 100]\n",
    "]\n",
    "p_valeus = [\n",
    "    ttest_ind(\n",
    "        cnv_topk.loc[(cnv_topk[\"K\"]==k) & (cnv_topk[\"Method\"]==\"RF\")][\"Value\"],\n",
    "        cnv_topk.loc[(cnv_topk[\"K\"]==k) & (cnv_topk[\"Method\"]==\"MIL\")][\"Value\"],\n",
    "    ).pvalue\n",
    "    for k in [1, 2, 3, 4, 5, 10, 15, 20, 100]\n",
    "]\n",
    "add_stat_annotation(\n",
    "    axes[3],\n",
    "    data=cnv_topk,\n",
    "    x=\"K\",\n",
    "    y=\"Value\",\n",
    "    hue=\"Method\",\n",
    "    box_pairs=pairs,\n",
    "    perform_stat_test=False,\n",
    "    text_format='star',\n",
    "    loc='inside',\n",
    "    verbose=0,\n",
    "    comparisons_correction=None,\n",
    "    pvalues=p_valeus,\n",
    ")\n",
    "axes[3].set_title(\"Hit rate (CNV Only)\")\n",
    "\n",
    "for ax in axes:\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax.legend(handles, labels, loc=\"lower right\")\n",
    "    ax.set_ylim(0, 1.1)\n",
    "    \n",
    "plt.savefig(\"results/1_3_RF_vs_MIL.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3asc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
